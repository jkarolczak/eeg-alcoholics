{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = utils.read_data(\"train\")\n",
    "test = utils.read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(2137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = [(train[key]['ts'].to_numpy(), 1 if train[key]['class'] == \"a\" else 0) for key in train]\n",
    "test_sequences = [(test[key]['ts'].to_numpy(), 1 if test[key]['class'] == \"a\" else 0)for key in test]\n",
    "random.shuffle(test_sequences)\n",
    "val_sequences = test_sequences[:100]\n",
    "test_sequences = test_sequences[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 380)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_sequences), len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "        return dict(\n",
    "            sequence=torch.Tensor(sequence),\n",
    "            label=torch.tensor(label).long()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, val_sequences, test_sequences, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.val_sequences = val_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = EEGDataset(self.train_sequences)\n",
    "        self.val_dataset = EEGDataset(self.val_sequences)\n",
    "        self.test_dataset = EEGDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EP0CHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "data_module = EEGDataModule(train_sequences, val_sequences, test_sequences, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGModel(nn.Module):\n",
    "    def __init__(self, n_features = 64, n_classes = 2, n_hidden=256, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size = n_hidden,\n",
    "            num_layers = n_layers,\n",
    "            batch_first = True,\n",
    "            dropout = 0.4\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "\n",
    "        out = hidden[-1]\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGPredictior(pl.LightningModule):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = EEGModel(n_features, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.acc = Accuracy(task=\"binary\")\n",
    "\n",
    "    def forward(self, x, labels = None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, outputs = self(sequences, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.acc(predictions, labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "        return {\"loss\":loss, \"accuracy\":step_accuracy}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, outputs = self(sequences, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.acc(predictions, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "        return {\"loss\":loss, \"accuracy\":step_accuracy}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, outputs = self(sequences, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.acc(predictions, labels)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "        return {\"loss\":loss, \"accuracy\":step_accuracy}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGPredictior(n_features= 64, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a9aa8ac8bc4b9e5e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a9aa8ac8bc4b9e5e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename= \"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"EEG\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=checkpoint_callback,\n",
    "    max_epochs=N_EP0CHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | EEGModel         | 1.4 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "2 | acc       | BinaryAccuracy   | 0     \n",
      "-----------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.532     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 15/15 [00:00<00:00, 16.82it/s, v_num=7, train_loss=0.689, train_accuracy=0.700, val_loss=0.689, val_accuracy=0.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 15: 'val_loss' reached 0.68894 (best 0.68894), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 19.31it/s, v_num=7, train_loss=0.689, train_accuracy=0.500, val_loss=0.684, val_accuracy=0.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 30: 'val_loss' reached 0.68393 (best 0.68393), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 18.30it/s, v_num=7, train_loss=0.654, train_accuracy=0.800, val_loss=0.671, val_accuracy=0.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 45: 'val_loss' reached 0.67139 (best 0.67139), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 18.14it/s, v_num=7, train_loss=0.628, train_accuracy=0.750, val_loss=0.636, val_accuracy=0.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 60: 'val_loss' reached 0.63615 (best 0.63615), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 18.63it/s, v_num=7, train_loss=0.468, train_accuracy=0.900, val_loss=0.535, val_accuracy=0.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 75: 'val_loss' reached 0.53456 (best 0.53456), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 18.69it/s, v_num=7, train_loss=0.359, train_accuracy=0.900, val_loss=0.545, val_accuracy=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 90: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 18.59it/s, v_num=7, train_loss=0.243, train_accuracy=0.900, val_loss=0.531, val_accuracy=0.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 105: 'val_loss' reached 0.53093 (best 0.53093), saving model to 'C:\\\\Users\\\\Jurek\\\\Desktop\\\\ROBOTYKA3\\\\work\\\\eeg-alcoholics\\\\checkpoints\\\\best-checkpoint-v6.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 16.61it/s, v_num=7, train_loss=0.111, train_accuracy=0.950, val_loss=0.586, val_accuracy=0.730] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 120: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 18.17it/s, v_num=7, train_loss=0.0323, train_accuracy=1.000, val_loss=0.650, val_accuracy=0.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 135: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 16.69it/s, v_num=7, train_loss=0.0389, train_accuracy=1.000, val_loss=0.806, val_accuracy=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 150: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 16.64it/s, v_num=7, train_loss=0.0389, train_accuracy=1.000, val_loss=0.806, val_accuracy=0.750]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at C:\\Users\\Jurek\\Desktop\\ROBOTYKA3\\work\\eeg-alcoholics\\checkpoints\\best-checkpoint-v6.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at C:\\Users\\Jurek\\Desktop\\ROBOTYKA3\\work\\eeg-alcoholics\\checkpoints\\best-checkpoint-v6.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7736842036247253     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.537832498550415     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7736842036247253    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.537832498550415    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.537832498550415, 'test_accuracy': 0.7736842036247253}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(dataloaders=data_module.test_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
